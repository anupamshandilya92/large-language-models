{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65889918",
   "metadata": {
    "papermill": {
     "duration": 0.007212,
     "end_time": "2024-12-27T20:02:05.826042",
     "exception": false,
     "start_time": "2024-12-27T20:02:05.818830",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "This notebook is part of a series in which we will explore different state-of-the-art techniques that have been recently developed and are used for building LLM applications. We go over high-level concepts used in fine-tuning an LLM model, and build a pipeline to fine-tune Google's Gemma 2 model.\n",
    "\n",
    "## 1. Introduction \n",
    "Large Language Models (LLM), in essence are very huge neural networks containing billions of parameters. In recent years, LLMs have have demonstrated remarkable success in a lot of tasks like text generation, chat bots, code generation etc. A lot of new techniques have been developed for training these models and adapting them for specific applications. In this notebook we aim to cover one of these techniques, viz. Fine Tuning LLM. This guide focuses on the fine-tuning process of a Large Language Model for English-to-Hindi translation tasks. a Large Language Model for English to Hindi translation task. In this notebook we fine-tune Gemma 2b, a two-billion parameter small-LLM developed by Google. We utilize a Hindi-English translation dataset to improve performance of Gemma 2-2b model on Hindi to English machine translation task. We make use of open-source dataset curated by Computation for Indian Language Technology (CFILT), IIT Bombay. This dataset is a collection of around 1,659,083 English sentences and their Hindi translations. We cover the details of this dataset in a later section.\n",
    "\n",
    "Gemma 2 is a family of lightweight open-source LLM released by Google in 2024. They are  decoder-only large language models, available in English. Gemma models are well-suited for a variety of text-generation tasks, including question-answering, summarization, and reasoning. Gemma 2 has models in sizes: 2 billion, 9 billion and 27 billion parameters.\n",
    "\n",
    "### Motivation for Hindi-English Translation\n",
    "Hindi is one of the low-resource language with limited support across LLM models. The complexities of grammatical structures, vocabulary differences, cultural contexts, script variations, and syntactic intricacies make English to Hindi translation a challenging yet fascinating task. Our goal is to see how well Gemma performs on this task, and how much can we improve its performance by fine-tuning it with a small dataset.\n",
    "\n",
    "\n",
    "### Why Fine-Tune an LLM?\n",
    "LLMs are trained using a large corpus of datasets. They are able to answer general questions about a variety of topics. More often we are interested in utilizing LLMs for specific tasks like question-answering, information retrieval from organization's documents, building chatbots for customer service, machine translation of text from one language to another, etc. among others. These applications require us to update the knowledge of LLMs using relevant datasets. Two prominent methods used to improve an existing pre-trained model for specific tasks are fine-tuning and retrieval augmented generation (RAG). A RAG pipeline augments LLM by using a retrieved-context (relevant text) from an existing database/datasource. We store relevant documents in a database (usually a vector database), and query this database to get this relevant text based on how similar it is to our prompt. Then retrieved-context is added to the original prompt and passed to LLM, this provides additional information to LLM to generate its response. \n",
    "    \n",
    "Fine-tuning involves adapting a pre-trained model to a specific task. It helps improve LLM's capabilities on domain-specific datasets that were not used in training the model. In this, we update parameters (also called weights) from a few or all layers of the neural network model (LLM). This is done by using a labeled dataset related to a specific task to train the model to update its parameters. This enables the fine-tuned model to have better performance for the specific task. \n",
    "\n",
    "LLMs have a lot of parameters (weights). Fine-tuning an LLM model and updating of all of its parameters can be a tedious task requiring a lot of time and computation resources. The Gemma 2 2B that is being used in this notebook has 2,617,270,528 parameters! Updating all parameters will be a resource-heavy process that will take up a lot of time. To get around the time and compute resource limitation, we make use of a new method called Low-Rank Adaptation (LoRA). This technique, in summary, helps lower the number of trained weights needed by a lot, making fine-tuning more accessible on smaller machines. \n",
    "\n",
    "Once we have fine-tuned the model, for evaluation, we compare the performance of baseline Gemma 2b model with the fine-tuned model using BLEU score, a commonly used metrics for machine translation task, to see how much does the model improve with our fine tuning. Manual evaluations by Human evaluators is more rigorous for machine translation tasks, but it is expensive. So in this exercise we rely on offline metrics like BLEU score. The evaluation code and results are available in the notebook named Gemma-English-Hindi Evaluation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e495efd",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:05.841633Z",
     "iopub.status.busy": "2024-12-27T20:02:05.841331Z",
     "iopub.status.idle": "2024-12-27T20:02:47.076928Z",
     "shell.execute_reply": "2024-12-27T20:02:47.076001Z"
    },
    "papermill": {
     "duration": 41.251701,
     "end_time": "2024-12-27T20:02:47.085509",
     "exception": false,
     "start_time": "2024-12-27T20:02:05.833808",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install Keras 3 last. See https://keras.io/getting_started/ for more details.\n",
    "!pip install -q -U keras-nlp datasets\n",
    "!pip install -q -U keras\n",
    "\n",
    "import os\n",
    "import keras_nlp\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TrainingArguments, pipeline\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d7faaa3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:47.100196Z",
     "iopub.status.busy": "2024-12-27T20:02:47.099633Z",
     "iopub.status.idle": "2024-12-27T20:02:47.104018Z",
     "shell.execute_reply": "2024-12-27T20:02:47.103255Z"
    },
    "papermill": {
     "duration": 0.013429,
     "end_time": "2024-12-27T20:02:47.105545",
     "exception": false,
     "start_time": "2024-12-27T20:02:47.092116",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Configs \n",
    "# Set the backbend before importing Keras\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Avoid memory fragmentation on JAX backend.\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.00\"\n",
    "\n",
    "model_id = \"gemma2_instruct_2b_en\"\n",
    "token_limit = 256\n",
    "\n",
    "# Run at half precision.\n",
    "#keras.config.set_floatx(\"bfloat16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41307d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:47.119521Z",
     "iopub.status.busy": "2024-12-27T20:02:47.119260Z",
     "iopub.status.idle": "2024-12-27T20:02:47.123425Z",
     "shell.execute_reply": "2024-12-27T20:02:47.122729Z"
    },
    "papermill": {
     "duration": 0.012965,
     "end_time": "2024-12-27T20:02:47.124980",
     "exception": false,
     "start_time": "2024-12-27T20:02:47.112015",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def calculate_bleu_score(reference, candidate):\n",
    "    reference_tokens = word_tokenize(reference)\n",
    "    candidate_tokens = word_tokenize(candidate)\n",
    "\n",
    "    return sentence_bleu([reference_tokens], candidate_tokens)\n",
    "\n",
    "def clean_model_output(txt):\n",
    "    \"\"\"Removes the control tokens from model output \"\"\"\n",
    "    txt = txt[txt.find('model') + 6 : -14]\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9435228c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:47.138780Z",
     "iopub.status.busy": "2024-12-27T20:02:47.138492Z",
     "iopub.status.idle": "2024-12-27T20:02:47.142651Z",
     "shell.execute_reply": "2024-12-27T20:02:47.141858Z"
    },
    "papermill": {
     "duration": 0.012811,
     "end_time": "2024-12-27T20:02:47.144222",
     "exception": false,
     "start_time": "2024-12-27T20:02:47.131411",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Helpers : https://github.com/google-gemini/gemma-cookbook/blob/main/Gemma/Advanced_Prompting_Techniques.ipynb\n",
    "def convert_message_to_prompt(message: str, model_prefix: str = \"\") -> str:\n",
    "    \"\"\"Converts a message to a prompt for a large language model.\n",
    "\n",
    "    Args:\n",
    "        message: The message to convert (str).\n",
    "        model_prefix: An optional prefix to prepend to the model response (str).\n",
    "\n",
    "    Returns:\n",
    "        A string containing the prompt for the large language model (str).\n",
    "    \"\"\"\n",
    "\n",
    "    return (\n",
    "        f\"<start_of_turn>user\\n Translate the sentence into hindi and only return the translation. Text :  {message}<end_of_turn>\\n\"\n",
    "        f\"<start_of_turn>model\\n{model_prefix}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee5d18f",
   "metadata": {
    "papermill": {
     "duration": 0.006266,
     "end_time": "2024-12-27T20:02:47.157035",
     "exception": false,
     "start_time": "2024-12-27T20:02:47.150769",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Dataset Details\n",
    "\n",
    "We use IIT Bombay English-Hindi parallel corpus in this notebook. This dataset is curated Center for Indian Language Technology, IIT Bombay. The training corpus consists of sentences, phrases as  well as dictionary entries, spanning many applications and domains. The corpus includes over 1.66 million sentence pairs. It has been compiled from a variety of existing sources like OPUS, HindEn, GNOME, KDE, Tanzil, Tatoeba, OpenSubs2013, HindEnCorp, Hindi-English Wordnet, Mahashabdkosh, TED talks, judicial domains, Indian government websites, Wiki headlines, and book translations.\n",
    "\n",
    "The inclusion of data from wide range of sources in this dataset ensures a rich variety of language use cases. This dataset is not tokenized, allowing users to process it according to their specific needs. It also includes monolingual Hindi and English corpora, which can be useful for additional language modeling tasks.\n",
    "\n",
    "Hindi language is based upon Devanagari script. It has around 48 basic alphabets consisting of 14 vowels and 34 consonants. It further has 20 diactrics that modify the consonants. Gemma is trained with english dataset, it has some tokens from devanagari script and can perform basic translation. Though, fine-tuning model will not increase the vocabulary to include more tokens in Devanagari script, it may improve model's understanding of Hindi language.\n",
    "\n",
    "The diverse range of sources ensures that the model is exposed to various writing styles and domains, enhancing its robustness. This exposure provides a rich vocabulary and a wide array of linguistic structures, which are crucial for training effective translation models. By incorporating texts from different domains (e.g., legal, administrative, technical), the model can better understand context-specific language use, thereby improving translation accuracy. Additionally, the inclusion of monolingual data allows the model to better grasp the nuances of each language, leading to more natural and accurate translations.\n",
    "\n",
    "This dataset can be downloaded from HuggingFace datasets hub. It comes with the sentences split into training, eval, and test sets, consisting of 1,492,827 and 520 and 2507 segments respectively.\n",
    "\n",
    "See https://www.cfilt.iitb.ac.in/iitb_parallel/ and Kunchukuttan et al. 2018 for more details on the dataset collection methods.\n",
    "\n",
    "References:\n",
    "1. Kunchukuttan, A., Mehta, P., & Bhattacharyya, P. (2018). The IIT Bombay English-Hindi Parallel Corpus. In Proceedings of the Eleventh International Conference on Language Resources and Evaluation (LREC 2018). European Language Resources Association (ELRA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8cc7523",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:47.170830Z",
     "iopub.status.busy": "2024-12-27T20:02:47.170507Z",
     "iopub.status.idle": "2024-12-27T20:02:55.363437Z",
     "shell.execute_reply": "2024-12-27T20:02:55.362464Z"
    },
    "papermill": {
     "duration": 8.201921,
     "end_time": "2024-12-27T20:02:55.365383",
     "exception": false,
     "start_time": "2024-12-27T20:02:47.163462",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1659083, 1)\n",
      "(520, 1)\n",
      "(2507, 1)\n"
     ]
    }
   ],
   "source": [
    "splits = {\n",
    "    \"train\": \"data/train-00000-of-00001.parquet\",\n",
    "    \"validation\": \"data/validation-00000-of-00001.parquet\",\n",
    "    \"test\": \"data/test-00000-of-00001.parquet\",\n",
    "}\n",
    "\n",
    "# load the parquet files from huggingface\n",
    "train = pd.read_parquet(\n",
    "    \"hf://datasets/cfilt/iitb-english-hindi/\" + splits[\"train\"]\n",
    ")\n",
    "val = pd.read_parquet(\n",
    "    \"hf://datasets/cfilt/iitb-english-hindi/\" + splits[\"validation\"]\n",
    ")\n",
    "test = pd.read_parquet(\n",
    "    \"hf://datasets/cfilt/iitb-english-hindi/\" + splits[\"test\"]\n",
    ")\n",
    "\n",
    "print(train.shape)\n",
    "print(val.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0127d711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:55.380377Z",
     "iopub.status.busy": "2024-12-27T20:02:55.379894Z",
     "iopub.status.idle": "2024-12-27T20:02:55.385957Z",
     "shell.execute_reply": "2024-12-27T20:02:55.385199Z"
    },
    "papermill": {
     "duration": 0.015007,
     "end_time": "2024-12-27T20:02:55.387446",
     "exception": false,
     "start_time": "2024-12-27T20:02:55.372439",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'en': 'Highlight border color', 'hi': 'सीमांत (बोर्डर) के रंग को हाइलाइट करें'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.iloc[7,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32569187",
   "metadata": {
    "papermill": {
     "duration": 0.006345,
     "end_time": "2024-12-27T20:02:55.400445",
     "exception": false,
     "start_time": "2024-12-27T20:02:55.394100",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Model details: Gemma 2\n",
    "\n",
    "Gemma is a family of lightweight, state-of-the-art open models from Google. They are built from the same research and technology used to create the Gemini models, but unlike Gemini models these Gemma models are open models that are available for free. They are text-to-text, decoder-only large language models, available in English, pre-trained variants, and instruction-tuned variants. Gemma models are well-suited for a variety of text-generation tasks, including question-answering, summarization, and reasoning. Their relatively small size makes it possible to deploy them in environments with limited resources such as a laptop, desktop or your own cloud infrastructure, democratizing access to state-of-the art AI models and helping foster innovation for everyone.\n",
    "\n",
    "See https://developers.googleblog.com/en/gemma-explained-overview-gemma-model-family-architectures/ for architecture of Gemma models. Below we cover some highlights and training details.\n",
    "\n",
    "**Key Architecture Highlights**:\n",
    "\n",
    "1. GeGlu activation : GeGLU for non linearity. Gated Linear Unit with GELU activation as given below:  $$GeGLU(x) = x*sigmoid(x) + x 0.5 (1 + tanh[sqrt(2/pi) (x + 0.044715 x³)])$$ This activation function is a combination of Gated Linear Units (GLU)  and Gaussian Error Linear Units (GELU). For an input 𝑥, the GeGLU is defined as:\n",
    "$$GeGLU(𝑥)=GLU(GELU(𝑥))$$\n",
    "This means the input 𝑥 is first passed through a GELU activation, and the resulting output is then modulated by a GLU. GLU introduces gating mechanisms to control information flow, enhancing learning.\n",
    "GELU provides smooth, differentiable activations that effectively modulate the input. GeGLU combines GLU and GELU, leveraging the strengths of both to model complex, non-linear patterns in the data.\n",
    "    1. Gated Linear Units (GLUs) are a type of activation function that enhances the learning capabilities of neural networks by introducing a gating mechanism. The GLUs use gates to control the flow of information through the network. It has two parts, the input transformation (x * W + b) and a gating mechanism, sigmoid(x * V + c). The sigmoid part controls the flow of information, if it is close to 1 the correspoding elements (x * W + b) passes, if sigmoid is close to 0, (x * W + b) is suppressed. This gating allows the network to focus on relevant features and ignore irrelevant ones, leading to more efficient learning and better generalization.\n",
    "$$\n",
    "\\text{GLU}(x) = (x * W + b) \\odot \\sigma(x * V + c)\n",
    "$$\n",
    "where, 𝑥 is the input vector.\n",
    "       𝑊 and 𝑉 are weight matrices learnt during training.\n",
    "       𝑏 and 𝑐 are bias vectors.\n",
    "       𝜎 is the sigmoid function.\n",
    "       ⊙ denotes element-wise multiplication.\n",
    "\n",
    "    2. Gaussian Error Linear Units (GELUs) are an activation function that combines the properties of linear and nonlinear activations. GELUs are known for their smoothness (in contrast to RELUs that switches abruptly between 0 and positive value) that and differentiability, which helps in training deep neural networks more effectively. \n",
    "$$\n",
    "\\text{GELU}(x) = x \\cdot \\Phi(x) = x \\cdot \\frac{1}{2} \\left[1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right]\n",
    "$$\n",
    " where, Φ(𝑥) is the standard Gaussian cumulative distribution function.\n",
    "        erf is the error function.\n",
    "    \n",
    "        - The term 0.5 * [ 1 + erf(x/sqrt(2))] acts like a gating mechanism. For large positive values of 𝑥, this term approaches 1, allowing 𝑥 to pass through almost unchanged. For large negative values of 𝑥, this term approaches 0, suppressing 𝑥. For values of 𝑥 near 0, the output is a fraction of 𝑥. \n",
    "\n",
    "        - GELU modulates the input based on the Gaussian CDF, scaling the input values smoothly. For large positive inputs, the activation approaches the input value, while for large negative inputs, it approaches zero. For inputs around zero, the activation is scaled down proportionally. This scaling helps the network focus on relevant features while suppressing less important ones.\n",
    "\n",
    "2. RoPe positional embeddings : Positional Encodings are used in transformer models to incorporate the order of the tokens (words or characters) in a sequence. They provide essential information about the position of tokens, helping the model understand the order and structure of the sequence and are added to token embeddings before feeding them into the transformer layers. ROPE embeddings make use a rotation matrix that helps capture the relative positions between tokens.\n",
    "   \n",
    "3. Multi Query Attention/Grouped-Query Attention (Ainslie et al., 2023): The attention mechanism allows the model to focus on different parts of the input sequence when making predictions. They make use of 3 matrices learnt during training for this, Query, Key and Value. The input embeddings are multiplied with these matrices to get Query vector, Key vector and Value vector. Instead of using a single attention mechanism, the models use multiple attention heads. Each head independently performs the attention mechanism on the input sequence. Multi Query Attention is a more memory-efficient variant of multi-head attention, where keys and values are shared across all heads, leading to reduced memory bandwidth requirements and improved efficiency during inference\n",
    "   \n",
    "4. RMSNorm : Root Mean Square Layer Normalization, is a technique used to stabilize the training of deep neural networks by normalizing the inputs to each layer. It simplifies the traditional Layer Normalization by removing the mean-centering operation and instead normalizing layer activations using the RMS statistic.\n",
    " \n",
    "5. Interleaving global and local attention layers (Beltagy et al., 2020): Interleaving global and local attention layers is a technique used in neural network architectures to effectively capture both local and global contextual information. Local attention focuses on capturing relationships and interactions between nearby nodes or tokens in the input sequence. It helps in understanding fine-grained details and local structures.Global Attention focuses on capturing relationships and interactions between distant nodes or tokens. It helps in understanding broader context and global structures.\n",
    "     \n",
    "\n",
    "\n",
    "**Training Highlights**:\n",
    "1. Pretraining with 3 trillion tokens primarily-English data from web documents, mathematics, and code.\n",
    "   \n",
    "2. Sentence piece token/byte level tokenization for unknown tokens :  It splits digits, does not remove extra whitespace, and relies on byte-level encodings for unknown tokens.\n",
    "   \n",
    "4. Teacher-student training with 27b model : Knowledge Distillation (Hinton et al., 2015) is a recent technique used to train a small model using a larger model as a teacher (27b Gemma 2 in this case). The smaller model (referred to as student model) is trained using the larger model's (teacher model) output probabilities. This preserves critical knowledge, ensures a smooth and effective training process, and enables smaller models to retain larger model's language capabilities.\\\n",
    "   \n",
    "5. Dictionary size : The vocabulary size of an LLM refers to the number of unique tokens (words, subwords, or characters) that the model can recognize and generate. The vocabulary size  for Gemma 2 is 256k tokens.\n",
    "   \n",
    "6. Instruction fine-tuning : After pre-training, the Gemma models are instruction-tuned using supervised fine-tuning (SFT) using a combination of text-only, English-only synthetic and human-created prompt-response pairs. Next, the models are further improved using  Reinforcement Learning from Human Feedback (RLHF), leveraging a reward model trained on labeled English-only preference data and applying the same prompts used during the SFT phase.\n",
    "\n",
    "\n",
    "**References**: \n",
    "1. Gemma Team. (2024). Gemma 2: Improving Open Language Models at a Practical Size.\n",
    "2. Hendrycks, D., & Gimpel, K. (2016). Gaussian Error Linear Units (GELUs). https://doi.org/10.48550/arXiv.1606.08415\n",
    "3. Shazeer, N. (2020). GLU Variants Improve Transformer. https://doi.org/10.48550/arXiv.2002.05202\n",
    "4. Hinton, G., Vinyals, O., & Dean, J. (2015). Distilling the knowledge in a neural network. \n",
    "5. Su, J., Lu, Y., Pan, S., Murtadha, A., Wen, B., & Liu, Y. (2021). RoFormer: Enhanced Transformer with Rotary Position Embedding. \n",
    "6. Beltagy, E., & Smith, N. A. (2020). Longformer: The Long-Document Transformer.\n",
    "7. Ainslie, J., Lee-Thorp, J., de Jong, M., Zemlyanskiy, Y., Lebrón, F., & Sanghai, S. (2023). GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eeb138d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:02:55.414560Z",
     "iopub.status.busy": "2024-12-27T20:02:55.414319Z",
     "iopub.status.idle": "2024-12-27T20:03:45.907566Z",
     "shell.execute_reply": "2024-12-27T20:03:45.906664Z"
    },
    "papermill": {
     "duration": 50.502246,
     "end_time": "2024-12-27T20:03:45.909346",
     "exception": false,
     "start_time": "2024-12-27T20:02:55.407100",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "device_name = tf.test.gpu_device_name()\n",
    "with tf.device('/GPU:0'):\n",
    "    gemma_lm = keras_nlp.models.GemmaCausalLM.from_preset(model_id)\n",
    "    gemma_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2647d49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:03:45.925608Z",
     "iopub.status.busy": "2024-12-27T20:03:45.925322Z",
     "iopub.status.idle": "2024-12-27T20:03:45.930383Z",
     "shell.execute_reply": "2024-12-27T20:03:45.929638Z"
    },
    "papermill": {
     "duration": 0.015109,
     "end_time": "2024-12-27T20:03:45.932032",
     "exception": false,
     "start_time": "2024-12-27T20:03:45.916923",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tick_start = 0\n",
    "\n",
    "def tick():\n",
    "    global tick_start\n",
    "    tick_start = time.time()\n",
    "\n",
    "def tock():\n",
    "    print(f\"TOTAL TIME ELAPSED: {time.time() - tick_start:.2f}s\")\n",
    "\n",
    " \n",
    "def text_gen(prompt, debug = False):\n",
    "    input = convert_message_to_prompt(prompt)\n",
    "    if debug:\n",
    "        print(f'User input: {input}')\n",
    "    output = gemma_lm.generate(input, max_length=token_limit)\n",
    "    if debug:\n",
    "        print(\"\\nGemma output:\")\n",
    "        print(output)\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52974dc3-45a6-41d7-8be2-46e4f2b98b4b",
   "metadata": {},
   "source": [
    "### Example of Model Inference Prompting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41e2d05b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:03:45.948097Z",
     "iopub.status.busy": "2024-12-27T20:03:45.947821Z",
     "iopub.status.idle": "2024-12-27T20:04:09.767579Z",
     "shell.execute_reply": "2024-12-27T20:04:09.766498Z"
    },
    "papermill": {
     "duration": 23.830014,
     "end_time": "2024-12-27T20:04:09.769432",
     "exception": false,
     "start_time": "2024-12-27T20:03:45.939418",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User input: <start_of_turn>user\n",
      " Translate the sentence into hindi and only return the translation. Text :  'Highlight border color'<end_of_turn>\n",
      "<start_of_turn>model\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735329835.972142      23 service.cc:145] XLA service 0x56731300cae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1735329835.972205      23 service.cc:153]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n",
      "I0000 00:00:1735329849.244335      23 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Gemma output:\n",
      "<start_of_turn>user\n",
      " Translate the sentence into hindi and only return the translation. Text :  'Highlight border color'<end_of_turn>\n",
      "<start_of_turn>model\n",
      "बर्गर रेखा रंग \n",
      "<end_of_turn>\n",
      "TOTAL TIME ELAPSED: 23.82s\n"
     ]
    }
   ],
   "source": [
    "# inference before fine-tuning\n",
    "tick()\n",
    "txt = text_gen(\"'Highlight border color'\", debug = True)\n",
    "tock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "959d68ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:04:09.786876Z",
     "iopub.status.busy": "2024-12-27T20:04:09.786471Z",
     "iopub.status.idle": "2024-12-27T20:04:09.792626Z",
     "shell.execute_reply": "2024-12-27T20:04:09.791811Z"
    },
    "papermill": {
     "duration": 0.016532,
     "end_time": "2024-12-27T20:04:09.794202",
     "exception": false,
     "start_time": "2024-12-27T20:04:09.777670",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'en': 'Highlight border color', 'hi': 'सीमांत (बोर्डर) के रंग को हाइलाइट करें'}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Original translation\n",
    "train.iloc[7,:].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696fbb27-d83a-4340-862b-92bcc4dbaf22",
   "metadata": {},
   "source": [
    "From the above translation, we see that Gemma is able to translate parts of the sentence and generates some close meaning words रेखा for border and and रंग for color. But overall the translated sentence loses its meaning. We try to improve this by fine-tuning the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c9383d2",
   "metadata": {
    "papermill": {
     "duration": 0.007526,
     "end_time": "2024-12-27T20:04:09.809318",
     "exception": false,
     "start_time": "2024-12-27T20:04:09.801792",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Evaluating base model - blue score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "46f3b2c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:04:09.825363Z",
     "iopub.status.busy": "2024-12-27T20:04:09.825088Z",
     "iopub.status.idle": "2024-12-27T20:04:09.889479Z",
     "shell.execute_reply": "2024-12-27T20:04:09.888469Z"
    },
    "papermill": {
     "duration": 0.074384,
     "end_time": "2024-12-27T20:04:09.891129",
     "exception": false,
     "start_time": "2024-12-27T20:04:09.816745",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>{'en': 'Due to financial constraints Dhirubhai...</td>\n",
       "      <td>Due to financial constraints Dhirubhai had to ...</td>\n",
       "      <td>आर्थिक तंगी के कारण धीरूभाई को हाईस्कूल के बाद...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>{'en': 'Or they can choose not to have a devic...</td>\n",
       "      <td>Or they can choose not to have a device at all...</td>\n",
       "      <td>या फिर से कोई भी डिवाइस न लेना चुन सकते हैं, ब...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>{'en': 'However, following the recent murder o...</td>\n",
       "      <td>However, following the recent murder of Austra...</td>\n",
       "      <td>वैसे हाल ही में फुकेट में ऑस्ट्रेलियाई ट्रैवेल...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>{'en': 'Delta and JetBlue were among the airli...</td>\n",
       "      <td>Delta and JetBlue were among the airliners who...</td>\n",
       "      <td>डेल्टा और जेटब्लू उन एयरलाइन्स में से हैं, जिन...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>{'en': 'It was simply nothing I could have ima...</td>\n",
       "      <td>It was simply nothing I could have imagined.</td>\n",
       "      <td>सरल तौर कहें तो में इसमें से किसी भी कल्पना भी...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            translation  \\\n",
       "2121  {'en': 'Due to financial constraints Dhirubhai...   \n",
       "56    {'en': 'Or they can choose not to have a devic...   \n",
       "2479  {'en': 'However, following the recent murder o...   \n",
       "1292  {'en': 'Delta and JetBlue were among the airli...   \n",
       "1599  {'en': 'It was simply nothing I could have ima...   \n",
       "\n",
       "                                                english  \\\n",
       "2121  Due to financial constraints Dhirubhai had to ...   \n",
       "56    Or they can choose not to have a device at all...   \n",
       "2479  However, following the recent murder of Austra...   \n",
       "1292  Delta and JetBlue were among the airliners who...   \n",
       "1599       It was simply nothing I could have imagined.   \n",
       "\n",
       "                                                  hindi  \n",
       "2121  आर्थिक तंगी के कारण धीरूभाई को हाईस्कूल के बाद...  \n",
       "56    या फिर से कोई भी डिवाइस न लेना चुन सकते हैं, ब...  \n",
       "2479  वैसे हाल ही में फुकेट में ऑस्ट्रेलियाई ट्रैवेल...  \n",
       "1292  डेल्टा और जेटब्लू उन एयरलाइन्स में से हैं, जिन...  \n",
       "1599  सरल तौर कहें तो में इसमें से किसी भी कल्पना भी...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample = test.sample(100, random_state=42)\n",
    "train_sample = train.sample(100, random_state=42)\n",
    "print(test_sample.shape)\n",
    "test_sample[\"english\"] = test_sample.translation.apply(lambda x: x.get(\"en\"))\n",
    "test_sample[\"hindi\"] = test_sample.translation.apply(lambda x: x.get(\"hi\"))\n",
    "\n",
    "train_sample[\"english\"] = train_sample.translation.apply(lambda x: x.get(\"en\"))\n",
    "train_sample[\"hindi\"] = train_sample.translation.apply(lambda x: x.get(\"hi\"))\n",
    "test_sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "393ec09c",
   "metadata": {
    "papermill": {
     "duration": 0.007789,
     "end_time": "2024-12-27T20:04:09.906987",
     "exception": false,
     "start_time": "2024-12-27T20:04:09.899198",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Model inference for test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "862e2631",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:04:09.924019Z",
     "iopub.status.busy": "2024-12-27T20:04:09.923431Z",
     "iopub.status.idle": "2024-12-27T20:08:36.945943Z",
     "shell.execute_reply": "2024-12-27T20:08:36.944918Z"
    },
    "papermill": {
     "duration": 267.04128,
     "end_time": "2024-12-27T20:08:36.955997",
     "exception": false,
     "start_time": "2024-12-27T20:04:09.914717",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOTAL TIME ELAPSED: 150.47s\n",
      "TOTAL TIME ELAPSED: 116.54s\n"
     ]
    }
   ],
   "source": [
    "tick()\n",
    "test_sample[\"predictions_woft\"] = test_sample.english.apply(\n",
    "    lambda text: text_gen(f\"{text}\")\n",
    ")\n",
    "tock()\n",
    "\n",
    "tick()\n",
    "train_sample[\"predictions_woft\"] = train_sample.english.apply(\n",
    "    lambda text: text_gen(f\"{text}\")\n",
    ")\n",
    "tock()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea6d9436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:36.973914Z",
     "iopub.status.busy": "2024-12-27T20:08:36.973192Z",
     "iopub.status.idle": "2024-12-27T20:08:36.989737Z",
     "shell.execute_reply": "2024-12-27T20:08:36.988865Z"
    },
    "papermill": {
     "duration": 0.027525,
     "end_time": "2024-12-27T20:08:36.991519",
     "exception": false,
     "start_time": "2024-12-27T20:08:36.963994",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "      <th>english</th>\n",
       "      <th>hindi</th>\n",
       "      <th>predictions_woft</th>\n",
       "      <th>predictions_woft_clean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2121</th>\n",
       "      <td>{'en': 'Due to financial constraints Dhirubhai...</td>\n",
       "      <td>Due to financial constraints Dhirubhai had to ...</td>\n",
       "      <td>आर्थिक तंगी के कारण धीरूभाई को हाईस्कूल के बाद...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\n Translate the sentence i...</td>\n",
       "      <td>धन कमी के कारण दिरुभाई ने हाई स्कूल छोड़ दिया।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>{'en': 'Or they can choose not to have a devic...</td>\n",
       "      <td>Or they can choose not to have a device at all...</td>\n",
       "      <td>या फिर से कोई भी डिवाइस न लेना चुन सकते हैं, ब...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\n Translate the sentence i...</td>\n",
       "      <td>या वे कोई भी डिवाइस नहीं रखना चाह सकते हैं, इस...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>{'en': 'However, following the recent murder o...</td>\n",
       "      <td>However, following the recent murder of Austra...</td>\n",
       "      <td>वैसे हाल ही में फुकेट में ऑस्ट्रेलियाई ट्रैवेल...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\n Translate the sentence i...</td>\n",
       "      <td>हालांकि, पट्टू मशहूर यात्रा एजेंट मिशेल स्मिथ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1292</th>\n",
       "      <td>{'en': 'Delta and JetBlue were among the airli...</td>\n",
       "      <td>Delta and JetBlue were among the airliners who...</td>\n",
       "      <td>डेल्टा और जेटब्लू उन एयरलाइन्स में से हैं, जिन...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\n Translate the sentence i...</td>\n",
       "      <td>डेल्टा और जेटब्लू पहले ही प्लान भेज चुके हैं।</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>{'en': 'It was simply nothing I could have ima...</td>\n",
       "      <td>It was simply nothing I could have imagined.</td>\n",
       "      <td>सरल तौर कहें तो में इसमें से किसी भी कल्पना भी...</td>\n",
       "      <td>&lt;start_of_turn&gt;user\\n Translate the sentence i...</td>\n",
       "      <td>यह बस मेरे दिमाग में कल्पना कर पाने योग्य कुछ ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            translation  \\\n",
       "2121  {'en': 'Due to financial constraints Dhirubhai...   \n",
       "56    {'en': 'Or they can choose not to have a devic...   \n",
       "2479  {'en': 'However, following the recent murder o...   \n",
       "1292  {'en': 'Delta and JetBlue were among the airli...   \n",
       "1599  {'en': 'It was simply nothing I could have ima...   \n",
       "\n",
       "                                                english  \\\n",
       "2121  Due to financial constraints Dhirubhai had to ...   \n",
       "56    Or they can choose not to have a device at all...   \n",
       "2479  However, following the recent murder of Austra...   \n",
       "1292  Delta and JetBlue were among the airliners who...   \n",
       "1599       It was simply nothing I could have imagined.   \n",
       "\n",
       "                                                  hindi  \\\n",
       "2121  आर्थिक तंगी के कारण धीरूभाई को हाईस्कूल के बाद...   \n",
       "56    या फिर से कोई भी डिवाइस न लेना चुन सकते हैं, ब...   \n",
       "2479  वैसे हाल ही में फुकेट में ऑस्ट्रेलियाई ट्रैवेल...   \n",
       "1292  डेल्टा और जेटब्लू उन एयरलाइन्स में से हैं, जिन...   \n",
       "1599  सरल तौर कहें तो में इसमें से किसी भी कल्पना भी...   \n",
       "\n",
       "                                       predictions_woft  \\\n",
       "2121  <start_of_turn>user\\n Translate the sentence i...   \n",
       "56    <start_of_turn>user\\n Translate the sentence i...   \n",
       "2479  <start_of_turn>user\\n Translate the sentence i...   \n",
       "1292  <start_of_turn>user\\n Translate the sentence i...   \n",
       "1599  <start_of_turn>user\\n Translate the sentence i...   \n",
       "\n",
       "                                 predictions_woft_clean  \n",
       "2121    धन कमी के कारण दिरुभाई ने हाई स्कूल छोड़ दिया।   \n",
       "56    या वे कोई भी डिवाइस नहीं रखना चाह सकते हैं, इस...  \n",
       "2479  हालांकि, पट्टू मशहूर यात्रा एजेंट मिशेल स्मिथ ...  \n",
       "1292     डेल्टा और जेटब्लू पहले ही प्लान भेज चुके हैं।   \n",
       "1599  यह बस मेरे दिमाग में कल्पना कर पाने योग्य कुछ ...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample[\"predictions_woft_clean\"] = test_sample.predictions_woft.apply(\n",
    "    lambda text: clean_model_output(text)\n",
    ")\n",
    "train_sample[\"predictions_woft_clean\"] = train_sample.predictions_woft.apply(\n",
    "    lambda text: clean_model_output(text)\n",
    ")\n",
    "test_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8e768451",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:37.009094Z",
     "iopub.status.busy": "2024-12-27T20:08:37.008832Z",
     "iopub.status.idle": "2024-12-27T20:08:37.017531Z",
     "shell.execute_reply": "2024-12-27T20:08:37.016634Z"
    },
    "papermill": {
     "duration": 0.019376,
     "end_time": "2024-12-27T20:08:37.019177",
     "exception": false,
     "start_time": "2024-12-27T20:08:36.999801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hindi                     आर्थिक तंगी के कारण धीरूभाई को हाईस्कूल के बाद...\n",
       "predictions_woft_clean      धन कमी के कारण दिरुभाई ने हाई स्कूल छोड़ दिया। \n",
       "Name: 2121, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample.iloc[0,:][['hindi', 'predictions_woft_clean']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b104e016",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:37.036544Z",
     "iopub.status.busy": "2024-12-27T20:08:37.036292Z",
     "iopub.status.idle": "2024-12-27T20:08:37.149443Z",
     "shell.execute_reply": "2024-12-27T20:08:37.148508Z"
    },
    "papermill": {
     "duration": 0.123852,
     "end_time": "2024-12-27T20:08:37.151232",
     "exception": false,
     "start_time": "2024-12-27T20:08:37.027380",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average BLEU Score: 0.34\n",
      "Average BLEU Score: 0.32\n"
     ]
    }
   ],
   "source": [
    "test_sample[\"BLEU_Score\"] = test_sample[\n",
    "    [\"hindi\", \"predictions_woft_clean\"]\n",
    "].apply(\n",
    "    lambda inputs: calculate_bleu_score(inputs[0], inputs[1]), axis=1\n",
    ")\n",
    "train_sample[\"BLEU_Score\"] = train_sample[\n",
    "    [\"hindi\", \"predictions_woft_clean\"]\n",
    "].apply(\n",
    "    lambda inputs: calculate_bleu_score(inputs[0], inputs[1]), axis=1\n",
    ")\n",
    "print(f\"Average BLEU Score: {test_sample['BLEU_Score'].mean().round(2)}\")\n",
    "print(f\"Average BLEU Score: {train_sample['BLEU_Score'].mean().round(2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49497361",
   "metadata": {
    "papermill": {
     "duration": 0.007881,
     "end_time": "2024-12-27T20:08:37.167794",
     "exception": false,
     "start_time": "2024-12-27T20:08:37.159913",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### BLEU Score Interpretation \n",
    "\n",
    "The BLEU (Bilingual Evaluation Understudy) score is a metric used to evaluate the quality of machine-translated text by comparing it to one or more reference translations. The score ranges from 0 to 1, with 1 indicating a perfect match between the machine translation and the reference translation(s).\n",
    "\n",
    "What Does a BLEU Score of 0.33 Mean?\n",
    "A BLEU score of 0.33 (or 33) means that the machine translation has a moderate level of overlap with the reference translation(s). This score indicates that approximately one-third of the n-grams (contiguous sequences of words) in the machine-translated text match those in the reference translation(s).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbb55bd0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:37.184949Z",
     "iopub.status.busy": "2024-12-27T20:08:37.184645Z",
     "iopub.status.idle": "2024-12-27T20:08:37.191044Z",
     "shell.execute_reply": "2024-12-27T20:08:37.190177Z"
    },
    "papermill": {
     "duration": 0.016763,
     "end_time": "2024-12-27T20:08:37.192592",
     "exception": false,
     "start_time": "2024-12-27T20:08:37.175829",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU score: 0.6257106818159155\n"
     ]
    }
   ],
   "source": [
    "bleu_score = calculate_bleu_score(\n",
    "    test_sample.hindi[1599], test_sample.predictions_woft_clean[1599]\n",
    ")\n",
    "print(f\"BLEU score: {bleu_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e786b6c3",
   "metadata": {
    "papermill": {
     "duration": 0.007969,
     "end_time": "2024-12-27T20:08:37.209023",
     "exception": false,
     "start_time": "2024-12-27T20:08:37.201054",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Fine Tune Model \n",
    "\n",
    "\n",
    "What is fine-tuning?\n",
    "Pre-trained LLM models are good for general tasks. For using these models to specific tasks, english to hindi translation in our case,  we need to adapt LLM (Gemma 2b here) to the specific tasks. Fine-tuning is one such technique, where we update the model parameters using specific dataset (CFILT). \n",
    "The original Gemma 2 model is trained primarily using English, hence its vocabulary has limited tokens from other languages. As a result, though model is able to understand and translate sentences from other languages (like Hindi) to a resonable extent,  frequent hallucinations and mixing of English content would render the usability of the model limited. Our goal is to fine-tune this model using a Hindi-English translation dataset to improve the performance of this model in language translation task. LLM's have a lot of parameters, in our case 2 billion parameters, updating all of these would require a lot of time and compute resources. To get around this we only update only few of the parameters while fine-tuning. Parameter-efficient Fine-tuning (PEFT) is a technique, which involves freezing some of the pre-trained model's parameters and fine-tuning the last few layers or adding additional layers for specific task.\n",
    "\n",
    "We make use of a PEFT fine-tuning technique known as LoRA. Low-Rank Adaptation (LoRA) (Microsoft, 2022) is a technique used to fine-tune LLMs. This technique greatly reduces the number of trainable parameters for downstream tasks by freezing the weights of the model and inserting a smaller number of new weights into the model. LoRA fine-tuning is a faster and memory-efficient  process, and produces smaller model weights (a few hundred MBs), all while maintaining the quality of the model outputs. \n",
    "\n",
    "LoRA is related to principal component analysis or singular vector decomposition, where we approximate a high-dimensional matrix or dataset using a lower-dimensional representation. In this we decompose the weight changes, ΔW, into a lower-rank representation (we learn the decomposed matrices via backpropagation). During regular fine-tuning we update the matrix of weights entirely. Let W be the original weight matrix, and del(W) represent the weight updates. Then after fine-tuning the new weights W' = W + del(W). Aghajanyan, A et. al. in their paper argue that while matrix of a pre-trained model has a full rank (no redundant rows or columns), the weight matrix has a low intrinsic dimension when the model is adapted to a new task. This means the weights can be effectively represented or approximated by a low-dimension matrix while retaining most of its essential information or structure while fine-tuning. How this works in practice is we train two smaller matrices A and B such that our update matrix del(W) - A.B. Using the above notations, suppose our weight matrix has dimension (MxN), del(W) will also have the same dimension (AxB). We keep the original W matrix frozen and train two new matrices A and B, with dimensions Mxr and rxN, where r is parameter we specify. This reduces our number of trained parameter from MxN to (Mxr + rxN).\n",
    "\n",
    "$$ W \\approx A \\times B $$\n",
    "$$ where, W \\in \\mathbb{R}^{M \\times N},  \n",
    "A \\in \\mathbb{R}^{M \\times r}, and \n",
    "B \\in \\mathbb{R}^{r \\times N} \n",
    "$$\n",
    "\n",
    "![Alt Text](lora.jpeg)\n",
    "\n",
    "Numerical example: Suppose M is 100 and N is 200. W has dimensions (100x200). Under normal fine tuning del(W) will require us to update 20,000 parameters. Using LoRA with rank r = 5, we will learn two new matrices A with dimensions 100x5 and B with dimensions 5x200. This will reduce the number of parameters learned during fine-tuning to 500+1000 = 1500. \n",
    "\n",
    "Note: \n",
    "A full rank matrix is a matrix whose rank = min(n_row, n_columns). None of its rows or columns can be represented as a linear combination of its other rows or columns.\n",
    "Low rank matrix is one whose rows or columns can be represented as a linear combination of its other rows or columns. It stores redundant information.\n",
    "\n",
    "Thus, LoRA us to fine-tune a model faster by training two new smaller matrices without losing much information. Hu et al. provide an empirical comparison of LoRA finetuned and full-tuned models to show that LoRA fine-tuning achieves comparable performance. We enable Low-Rank Adaptation (LoRA) on the model's backbone with a specified rank using keras nlp API. The parameter r (rank) dictates the dimensions of the low-rank adaptation when factorizing weight matrices, thereby determining the size of the low-rank matrices. Consequently, rank significantly affects the number of trainable parameters (refer to the image). Larger rank values allow for a more precise approximation of the full model weights, enhancing accuracy. However, they also require more computational power and memory, leading to slower performance and a higher risk of overfitting. Conversely, smaller rank values prioritize efficient training at the expense of some performance. Commonly recommended values include [8, 16, 32, 64, 128, 256].\n",
    "\n",
    "For now, we are only tuning the parameter rank (r) in our LoRA adapter. \n",
    "\n",
    "In our case, using LoRA reduces trainable parameters from 2,628,985,088 (9.79 GB) to 14,643,200 (55.86 MB).\n",
    "\n",
    "References:\n",
    "1. Aghajanyan, A., Zettlemoyer, L., & Gupta, S. (2020). Intrinsic dimensionality explains the effectiveness of language model fine-tuning. arXiv preprint arXiv:2012.13255.\n",
    "2. Hu, E. J., Shen, Y., Wallis, P., Allen-Zhu, Z., Li, Y., Wang, S., Wang, L., & Chen, W. (2021). LoRA: Low-Rank Adaptation of Large Language Models. arXiv preprint arXiv:2106.09685."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e8d3c3-c2ab-47a2-9928-c6ff073b9b12",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "Control tokens in Gemma models: Below is the structure of prompt that is used by Gemma 2 models. <start_of_turn> and <end_of_turn> are the control tokens used in its prompts. See below for example.\n",
    "\n",
    "```\n",
    "User: \\<start_of_turn>userKnock knock.\\<end_of_turn>\n",
    "\\<start_of_turn>model Model:\tWho’s there?\\<end_of_turn>\n",
    "User:\t\\<start_of_turn>userGemma.\\<end_of_turn>\n",
    "<start_of_turn>modelModel:\tGemma who?\\<end_of_turn>\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "28da7ec4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:37.242337Z",
     "iopub.status.busy": "2024-12-27T20:08:37.242063Z",
     "iopub.status.idle": "2024-12-27T20:08:37.245961Z",
     "shell.execute_reply": "2024-12-27T20:08:37.245152Z"
    },
    "papermill": {
     "duration": 0.014361,
     "end_time": "2024-12-27T20:08:37.247510",
     "exception": false,
     "start_time": "2024-12-27T20:08:37.233149",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_prompt(col1, col2):\n",
    "    return f\"\"\"<start_of_turn>user\\n Translate the sentence into hindi and only return the translation. Text : {col1}<end_of_turn>\\n\n",
    "           <start_of_turn>model\\n{col2}<end_of_turn>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3268ecd5",
   "metadata": {
    "papermill": {
     "duration": 6.004163,
     "end_time": "2024-12-27T20:08:43.259818",
     "exception": false,
     "start_time": "2024-12-27T20:08:37.255655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "tokenizer = keras_nlp.models.GemmaTokenizer.from_preset(model_id)\n",
    "\n",
    "train[\"english\"] = train.translation.apply(lambda x: x.get(\"en\"))\n",
    "train[\"hindi\"] = train.translation.apply(lambda x: x.get(\"hi\"))\n",
    "df_train = train.sample(n = 2000, random_state = 123)\n",
    "\n",
    "df_train['prompt'] = df_train.apply(lambda row: get_prompt(row['english'], row['hindi']), axis=1)\n",
    "df_train['len_prompt'] = df_train['prompt'].apply(lambda x: len(tokenizer(x)))\n",
    "\n",
    "df_train = df_train[df_train['len_prompt']<token_limit].copy(deep=True)\n",
    "                                                  \n",
    "train_list = df_train['prompt'].tolist()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "613aa9a5-8e2a-42ab-8e41-f8009d40d449",
   "metadata": {},
   "source": [
    "### Training \n",
    "**Hyperparameters** : \n",
    "1. learning_rate : manually tuned to 0.001. It determines how big a step do we take towards the minimum in each step. After each epoch we update the weights/parameters by quantity equal to -(learning_rate * gradient of loss function wrt to parameter). If the learning rate is too high, the model might converge too quickly to a suboptimal solution (or not converge at all). If the learning rate is too low, the training process will be slow, and it might get stuck in local minima.\n",
    "\n",
    "2. Lora rank : As described above, this tells us the size of new low-rank matrices that are learned during the fine-tuning. A large rank means more parameters will be learned. Manually tuned to 20.\n",
    "\n",
    "**Loss Function**: \n",
    "LLMs are trained to predict the next token or word in sentence/sequence based on previous tokens. For each word prediction, the input sequences are passed through the model. The model outputs a vector (sequence of logits) that have the same size as the model's vocabulary. Softmax function converts these to multiclass probability, which can be roughly interpreted as the probability of each token to be the predicted word. As a simple method, we can choose the token with the highest probability to be the predicted token. So, for example, if the model vocab has 7 tokens, for every token/work that the model predicts we get a vector with 7 probabilities representing how likely our model thinks that each token is for that prediction. Below picture (Rashcka, 2024) explains this :\n",
    "\n",
    "![Alt Text](multiclasslogits.png)\n",
    "\n",
    "\n",
    "Categorical cross-entropy loss function is used for training/fine-tuning the model. This is well suited for multi-class classification problems. In the code below we use Sparse categorical cross-entropy loss. Sparse categorical cross entropy makes use of integer labels, whereas categorical cross entropy requires one-hot encoding. The loss function is given as follows:\n",
    "$$\n",
    "L = - \\sum_{i=1}^{N} \\sum_{c=1}^{C} p_{i,c} \\log(\\hat{p}_{i,c})\n",
    "$$\n",
    "\n",
    "$L$: **Loss** - The categorical cross-entropy loss, which measures how well the model's predictions match the true labels. Lower values indicate better performance.\n",
    "\n",
    "- $ N $: **Number of Samples** - The total number of data samples (or instances) in the dataset.\n",
    "- $ C $: **Number of Classes** - The total number of classes or categories in the classification problem.\n",
    "- $p_{i,c}$: **Ground Truth Label** - A binary indicator (1 or 0) that represents whether the \\( i \\)-th sample belongs to class \\( c \\). If the sample belongs to class \\( c \\), $p_{i,c} = 1$ ; otherwise, $p_{i,c} = 0 $.\n",
    "- $\\hat{p}_{i,c}$: **Predicted Probability** - The probability predicted by the model that the \\( i \\)-th sample belongs to class \\( c \\). It is the output of the softmax function for the \\( i \\)-th sample and class \\( c \\).\n",
    "\n",
    "References: \n",
    "\n",
    "1. Sebastian Raschka. LLMs from scratch. https://github.com/rasbt/LLMs-from-scratch/blob/main/ch05/01_main-chapter-code/ch05.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9385490c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:43.278083Z",
     "iopub.status.busy": "2024-12-27T20:08:43.277819Z",
     "iopub.status.idle": "2024-12-27T20:08:43.281553Z",
     "shell.execute_reply": "2024-12-27T20:08:43.280835Z"
    },
    "papermill": {
     "duration": 0.014496,
     "end_time": "2024-12-27T20:08:43.283093",
     "exception": false,
     "start_time": "2024-12-27T20:08:43.268597",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Training Configurations\n",
    "\n",
    "lora_name = \"llm_mark1\"\n",
    "lora_rank = 20\n",
    "lr_value = 0.001\n",
    "train_epoch = 20\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "57bd90e8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:43.300937Z",
     "iopub.status.busy": "2024-12-27T20:08:43.300659Z",
     "iopub.status.idle": "2024-12-27T20:08:43.508727Z",
     "shell.execute_reply": "2024-12-27T20:08:43.507894Z"
    },
    "papermill": {
     "duration": 0.218975,
     "end_time": "2024-12-27T20:08:43.510406",
     "exception": false,
     "start_time": "2024-12-27T20:08:43.291431",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                              │                      Vocab size: <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                              │                      Vocab size: \u001b[38;5;34m256,000\u001b[0m │\n",
       "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,628,985,088</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,628,985,088\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,628,985,088</span> (9.79 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,628,985,088\u001b[0m (9.79 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,643,200</span> (55.86 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m14,643,200\u001b[0m (55.86 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (9.74 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (9.74 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Enable LoRA for the model and set the LoRA rank to 4.\n",
    "gemma_lm.backbone.enable_lora(rank=20)\n",
    "gemma_lm.summary()\n",
    "\n",
    "# Limit the input sequence length (to control memory usage).\n",
    "gemma_lm.preprocessor.sequence_length = token_limit\n",
    "# Use AdamW (a common optimizer for transformer models).\n",
    "optimizer = keras.optimizers.AdamW(\n",
    "    learning_rate=lr_value,\n",
    "    weight_decay=0.01,\n",
    ")\n",
    "# Exclude layernorm and bias terms from decay.\n",
    "optimizer.exclude_from_weight_decay(var_names=[\"bias\", \"scale\"])\n",
    "\n",
    "gemma_lm.compile(\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    optimizer=optimizer,\n",
    "    weighted_metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf86615d",
   "metadata": {
    "papermill": {
     "duration": 0.008736,
     "end_time": "2024-12-27T20:08:43.528591",
     "exception": false,
     "start_time": "2024-12-27T20:08:43.519855",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Save LoRA for each epoch - we make use of a custom call back function to save LoRA weights after each epoch. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95d483ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-27T20:08:43.547490Z",
     "iopub.status.busy": "2024-12-27T20:08:43.547205Z",
     "iopub.status.idle": "2024-12-28T00:52:11.140761Z",
     "shell.execute_reply": "2024-12-28T00:52:11.139976Z"
    },
    "papermill": {
     "duration": 17007.605151,
     "end_time": "2024-12-28T00:52:11.142581",
     "exception": false,
     "start_time": "2024-12-27T20:08:43.537430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1735330171.758835      88 assert_op.cc:38] Ignoring Assert operator compile_loss/sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/assert_equal_1/Assert/Assert\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1735330190.275494      88 asm_compiler.cc:369] ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_9', 440 bytes spill stores, 512 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_7', 72 bytes spill stores, 120 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 12 bytes spill stores, 12 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function 'loop_add_subtract_fusion_5', 440 bytes spill stores, 512 bytes spill loads\n",
      "ptxas warning : Registers are spilled to local memory in function '__cuda_sm3x_div_rn_noftz_f32_slowpath', 24 bytes spill stores, 24 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m914s\u001b[0m 427ms/step - loss: 0.5416 - sparse_categorical_accuracy: 0.6214\n",
      "Epoch 2/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.5074 - sparse_categorical_accuracy: 0.6274\n",
      "Epoch 3/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m848s\u001b[0m 427ms/step - loss: 0.4660 - sparse_categorical_accuracy: 0.6465\n",
      "Epoch 4/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.4262 - sparse_categorical_accuracy: 0.6650\n",
      "Epoch 5/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.3997 - sparse_categorical_accuracy: 0.6765\n",
      "Epoch 6/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.3719 - sparse_categorical_accuracy: 0.6912\n",
      "Epoch 7/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.3461 - sparse_categorical_accuracy: 0.7072\n",
      "Epoch 8/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.3213 - sparse_categorical_accuracy: 0.7219\n",
      "Epoch 9/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.3005 - sparse_categorical_accuracy: 0.7361\n",
      "Epoch 10/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.2826 - sparse_categorical_accuracy: 0.7494\n",
      "Epoch 11/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.2601 - sparse_categorical_accuracy: 0.7659\n",
      "Epoch 12/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.2448 - sparse_categorical_accuracy: 0.7780\n",
      "Epoch 13/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.2280 - sparse_categorical_accuracy: 0.7919\n",
      "Epoch 14/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.2151 - sparse_categorical_accuracy: 0.8029\n",
      "Epoch 15/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.1936 - sparse_categorical_accuracy: 0.8229\n",
      "Epoch 16/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.1855 - sparse_categorical_accuracy: 0.8302\n",
      "Epoch 17/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.1720 - sparse_categorical_accuracy: 0.8434\n",
      "Epoch 18/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.1630 - sparse_categorical_accuracy: 0.8526\n",
      "Epoch 19/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.1545 - sparse_categorical_accuracy: 0.8602\n",
      "Epoch 20/20\n",
      "\u001b[1m1985/1985\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m847s\u001b[0m 427ms/step - loss: 0.1498 - sparse_categorical_accuracy: 0.8655\n"
     ]
    }
   ],
   "source": [
    "class CustomCallback(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    model_name = f\"/kaggle/working/{lora_name}_{lora_rank}_epoch{epoch+1}.lora.h5\"\n",
    "    gemma_lm.backbone.save_lora_weights(model_name)\n",
    "\n",
    "history = gemma_lm.fit(train_list,\n",
    "                       epochs=train_epoch,\n",
    "                       batch_size=1, \n",
    "                       callbacks=[CustomCallback()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b79fcb3",
   "metadata": {
    "papermill": {
     "duration": 2.309938,
     "end_time": "2024-12-28T00:52:15.439438",
     "exception": false,
     "start_time": "2024-12-28T00:52:13.129500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# A simple plot to visualize training loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.plot(history['epochs'],history['loss'])\n",
    "plt.scatter(history['epochs'],history['loss'])\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.xticks(history['epochs'])\n",
    "\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168a4406-e88c-4103-bd9b-528c928d9d34",
   "metadata": {},
   "source": [
    "## Notes:\n",
    "\n",
    "From the above plot, we see that the training loss decreases in later epochs. This gives an indication of that the model is learning from the training process.\n",
    "\n",
    "The evaluation of this fine-tuned model will be done in a following notebook. This notebook serves as reference code pipeline for fine tuning Gemma 2 using keras nlp library. We covered some of the key architectural details of Gemma 2 model, and  high-level topics related to training and fine-tuning LLMs. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4f8748-e35f-4e2e-8631-18be320c743b",
   "metadata": {},
   "source": [
    "##### Additional util functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "abbfbaad",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T00:52:19.505787Z",
     "iopub.status.busy": "2024-12-28T00:52:19.505422Z",
     "iopub.status.idle": "2024-12-28T00:52:20.290763Z",
     "shell.execute_reply": "2024-12-28T00:52:20.289924Z"
    },
    "papermill": {
     "duration": 2.82738,
     "end_time": "2024-12-28T00:52:20.292642",
     "exception": false,
     "start_time": "2024-12-28T00:52:17.465262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Util function to clean GPU \n",
    "import gc\n",
    "import ctypes\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "tf.keras.backend.clear_session()\n",
    "def clean_memory(deep=False):\n",
    "    gc.collect()\n",
    "    if deep:\n",
    "        ctypes.CDLL(\"libc.so.6\").malloc_trim(0)\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c2b0a996",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-28T00:52:24.338015Z",
     "iopub.status.busy": "2024-12-28T00:52:24.337611Z",
     "iopub.status.idle": "2024-12-28T00:52:25.068246Z",
     "shell.execute_reply": "2024-12-28T00:52:25.067332Z"
    },
    "papermill": {
     "duration": 2.7793,
     "end_time": "2024-12-28T00:52:25.069905",
     "exception": false,
     "start_time": "2024-12-28T00:52:22.290605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# del(gemma_lm)\n",
    "\n",
    "clean_memory()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6332047,
     "sourceId": 10239463,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6332048,
     "sourceId": 10239465,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6332485,
     "sourceId": 10240070,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6334381,
     "sourceId": 10242812,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 72246,
     "sourceId": 85986,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "dockerImageVersionId": 30804,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 17479.930589,
   "end_time": "2024-12-28T00:53:23.322648",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-27T20:02:03.392059",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
